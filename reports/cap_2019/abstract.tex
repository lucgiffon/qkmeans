\begin{abstract}
The K-means algorithm is a pivotal procedure for many tasks of machine learning and
data analysis such as indexing, nearest-neighbors prediction, clustering and it has
proved to be essential for improving the accuracy of the well-known Nyström approximation
procedure used to speed-up kernel machines, which is a motivation in the hindsight
of the present contribution. We here propose {\em Q-means}, an accelerated
version of $K$-means, that looks for the matrix $U$ of the $K$ centroids as a product
of sparse matrices.
%We propose a new algorithm called \textit{Q-means} for learning a matrix of K-means center-points which can be decomposed as a factorization of sparse matrices.
 This decomposition allows us to compute the matrix-vector product of the $U$ with any vector in time $\mathcal{O}(K log d)$ instead of $\mathcal{O}(Kd)$, where $d$ if the number of factors and the sparsity constraint are properly define -- NOT SURE WITH $d$. As evoked before, we show how our algorithm could be used in the context of the Nyström approximation. % to speed up its use in subsequent kernel machines.

This paper is a description of work in progress and as such does not contain experimental validation. We give the proposed algorithm with convergence proof, and discuss foreseen experiments and a scope of use.
\end{abstract}
