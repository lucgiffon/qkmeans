{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation palm4LED\n",
    "\n",
    "Magoarou, L. L., & Gribonval, R. (2014). Learning computationally efficient dictionaries and their implementation as fast transforms. arXiv preprint arXiv:1406.5388."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy import trace\n",
    "from numpy import identity\n",
    "from numpy import argpartition\n",
    "from numpy.linalg import multi_dot\n",
    "from scipy.linalg import hadamard\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projection_operator(input_arr, nb_keep_values):\n",
    "    \"\"\"\n",
    "    Project input_arr onto its nb_keep_values highest values\n",
    "    \"\"\"\n",
    "    flat_input_arr = input_arr.flatten()\n",
    "    # find the index of the lowest values (not the _nb_keep_values highest)\n",
    "    lowest_values_idx = argpartition(np.absolute(flat_input_arr), -nb_keep_values, axis=None)[:-nb_keep_values]\n",
    "    # set the value of the lowest values to zero\n",
    "    flat_input_arr[lowest_values_idx] = 0.\n",
    "    # return reshape_to_matrix\n",
    "    return flat_input_arr.reshape(input_arr.shape)\n",
    "\n",
    "def inplace_hardthreshold(input_arr, nb_keep_values):\n",
    "    \"\"\"\n",
    "    Hard-threshold input_arr by keeping its nb_keep_values highest values only\n",
    "    Variant without copy of input_arr (inplace changes)\n",
    "    \"\"\"\n",
    "    # find the index of the lowest values (not the _nb_keep_values highest)\n",
    "    lowest_values_idx = argpartition(np.absolute(input_arr), -nb_keep_values, axis=None)[:-nb_keep_values]\n",
    "    # set the value of the lowest values to zero\n",
    "    input_arr.reshape(-1)[lowest_values_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_side_prod(lst_factors, id_size=0):\n",
    "    \"\"\"\n",
    "    Return the dot product between factors in lst_factors in order.\n",
    "\n",
    "    exemple:\n",
    "\n",
    "    lst_factors := [S1, S2, S3]\n",
    "    return_value:= S1 @ S2 @ S3\n",
    "    \"\"\"\n",
    "    # assert if the inner dimension of factors match: e.g. the multi dot product is feasible\n",
    "    assert all([lst_factors[i].shape[-1] == lst_factors[i+1].shape[0] for i in range(len(lst_factors)-1)])\n",
    "\n",
    "    if len(lst_factors) == 0:\n",
    "        # convention from the paper itself: dot product of no factors equal Identity\n",
    "        side_prod = identity(id_size)\n",
    "    elif len(lst_factors) == 1:\n",
    "        # if only 1 elm, return the elm itself (Identity * elm actually)\n",
    "        side_prod = lst_factors[0]\n",
    "    else:\n",
    "        side_prod = multi_dot(lst_factors)\n",
    "    return side_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palm4msa(arr_X_target: np.array, \n",
    "             lst_S_init: list,\n",
    "             nb_factors: int, \n",
    "             lst_nb_keep_values: list, \n",
    "             f_lambda_init: float, \n",
    "             nb_iter: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    lst S init contains factors in decreasing indexes: S5 S4 S3 S2 S1\n",
    "    \n",
    "    lst S [-j] = Sj\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Norme de arr_X_target:', np.linalg.norm(arr_X_target, ord='fro'))\n",
    "    def update_S(S_old, _left_side, _right_side, _c, _lambda, _nb_keep_values):\n",
    "        \"\"\"\n",
    "        Return the new factor value.\n",
    "        \n",
    "        - Compute gradient\n",
    "        - Do gradient step\n",
    "        - Project data on _nb_keep_values highest entries\n",
    "        - Normalize data\n",
    "        \"\"\"\n",
    "        # compute gradient of the distance metric (with 1/_c gradient step size)\n",
    "        grad_step =  1./_c * _lambda * _left_side.T @ ((_lambda * _left_side @ S_old @ _right_side) - arr_X_target) @ _right_side.T\n",
    "        \n",
    "        # grad_step[np.abs(grad_step) < np.finfo(float).eps] = 0.\n",
    "        # 1 step for minimizing + flatten necessary for the upcoming projection\n",
    "        S_tmp = S_old - grad_step\n",
    "        # projection\n",
    "        # S_proj = projection_operator(S_tmp, _nb_keep_values)\n",
    "        inplace_hardthreshold(S_tmp, _nb_keep_values)\n",
    "        # normalize because all factors must have norm 1\n",
    "        S_proj = S_tmp\n",
    "        S_proj = S_proj / norm(S_proj, ord=\"fro\")\n",
    "        return S_proj\n",
    "        \n",
    "    assert len(lst_S_init) > 0\n",
    "    assert get_side_prod(lst_S_init).shape == arr_X_target.shape\n",
    "    assert len(lst_S_init) == nb_factors\n",
    "    # initialization\n",
    "    f_lambda = f_lambda_init\n",
    "    lst_S = deepcopy(lst_S_init)\n",
    "#     arr_X_curr = multi_dot(lst_S) # modified by VE\n",
    "#     f_lambda = np.linalg.norm(arr_X_target, ord='fro') / np.linalg.norm(arr_X_curr, ord='fro') # modified by VE\n",
    "#     f_lambda = trace(arr_X_target.T @ arr_X_curr) / trace(arr_X_curr.T @ arr_X_curr) # modified by VE\n",
    "    \n",
    "    objective_function = np.empty((nb_iter, nb_factors+1))\n",
    "    # main loop\n",
    "    for i_iter in range(nb_iter): \n",
    "#         print('Norme de la factorisation:', np.linalg.norm(f_lambda * multi_dot(lst_S), ord='fro'))\n",
    "        # todo critère d'arrêt delta erreur = 10^-6\n",
    "        for j in range(1, nb_factors+1):\n",
    "            #left_side = get_side_prod(lst_S[:j], arr_X_target.shape[0]) # L = products of all yet updated factors during this iter\n",
    "            #right_side = get_side_prod(lst_S[j+1:], arr_X_target.shape[0]) # R = products of all not yet updated factors\n",
    "            \n",
    "            left_side = get_side_prod(lst_S[:-j], arr_X_target.shape[0]) # L\n",
    "            right_side = get_side_prod(lst_S[nb_factors-j+1:], arr_X_target.shape[0]) # R\n",
    "#             print('j: {}/{}'.format(j, nb_factors))\n",
    "#             print('Left side', lst_S[:-j], len(lst_S[:-j]))\n",
    "#             print(norm(left_side, ord=2))\n",
    "#             print(lst_S[-j])\n",
    "#             print('Right side', lst_S[nb_factors-j+1:], len(lst_S[nb_factors-j+1:]))\n",
    "#             print(norm(right_side, ord=2))\n",
    "            \n",
    "            # compute minimum c value (according to paper)\n",
    "            min_c_value = (f_lambda * norm(right_side, ord=2) * norm(left_side, ord=2)) ** 2\n",
    "            # add epsilon because it is exclusive minimum\n",
    "            #c = min_c_value * (1+np.finfo(float).eps)\n",
    "            c = min_c_value * 1.001\n",
    "            #c = min_c_value + 1\n",
    "            \n",
    "            # compute new factor value\n",
    "            lst_S[-j] = update_S(lst_S[-j], left_side, right_side, c, f_lambda, lst_nb_keep_values[-j])\n",
    "\n",
    "            objective_function[i_iter, j-1] = np.linalg.norm(arr_X_target - f_lambda * multi_dot(lst_S), ord='fro')\n",
    "\n",
    "        # re-compute the full factorisation\n",
    "        if len(lst_S) == 1:\n",
    "            arr_X_curr = lst_S[0]\n",
    "        else:\n",
    "            arr_X_curr = multi_dot(lst_S)\n",
    "        # update lambda\n",
    "        f_lambda = trace(arr_X_target.T @ arr_X_curr) / trace(arr_X_curr.T @ arr_X_curr)\n",
    "        \n",
    "        objective_function[i_iter, -1] = np.linalg.norm(arr_X_target - f_lambda * multi_dot(lst_S), ord='fro')\n",
    "    \n",
    "    plt.figure()\n",
    "    for j in range(nb_factors+1): \n",
    "        plt.semilogy(objective_function[:, j], label=str(j))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return f_lambda, lst_S, arr_X_curr, objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hierarchical_palm4msa(arr_X_target: np.array, \n",
    "                         lst_S_init: list, \n",
    "                         nb_keep_values: int, \n",
    "                         f_lambda_init: float, \n",
    "                         nb_iter: int,\n",
    "                         \n",
    "                         residual_sparsity_decrease=None,\n",
    "                         residual_global_sparsity=None,\n",
    "                         right_to_left=True):\n",
    "    \n",
    "    # initialisation\n",
    "    if right_to_left:\n",
    "        arr_residual = arr_X_target\n",
    "    else: # attention: vérifier l'équivalence en prenant en compte le lambda\n",
    "        arr_residual = arr_X_target.T\n",
    "        lst_S_init = [S.T for S in lst_S_init[::-1]]\n",
    "        \n",
    "    lst_S = deepcopy(lst_S_init)\n",
    "    nb_factors = len(lst_S)\n",
    "    \n",
    "    if residual_sparsity_decrease is None:\n",
    "        residual_sparsity_decrese = 0.5\n",
    "    if residual_global_sparsity is None:\n",
    "        residual_global_sparsity = min(arr_X_target.shape) ** 2\n",
    "        \n",
    "    nb_keep_values_relaxed = residual_global_sparsity\n",
    "    \n",
    "    # main loop\n",
    "    for k in range(nb_factors-1):\n",
    "        nb_factors_so_far = k+1\n",
    "        if nb_factors_so_far == nb_factors-1:\n",
    "            nb_keep_values_relaxed = nb_keep_values\n",
    "        else:\n",
    "            nb_keep_values_relaxed *= residual_sparsity_decrese\n",
    "        print(\"working on factor:\", k)\n",
    "        # define constraints: ||0 = d pour T1; no constraint on ||0 for T2\n",
    "        lst_nb_keep_values_constraints = [int(nb_keep_values_relaxed), nb_keep_values]\n",
    "        # calcule decomposition en 2 du dernier résidu de l'opération précédente\n",
    "        residual_init = get_side_prod(lst_S_init[:-nb_factors_so_far])\n",
    "        f_lambda_prime, (F2, F1), _, _ = palm4msa(arr_X_target=arr_residual, \n",
    "                                                  lst_S_init=[residual_init, lst_S_init[-nb_factors_so_far]],\n",
    "                                               nb_factors=2,\n",
    "                                               lst_nb_keep_values=lst_nb_keep_values_constraints, \n",
    "                                               f_lambda_init=f_lambda_init, \n",
    "                                               nb_iter=nb_iter)\n",
    "\n",
    "        lst_S[-nb_factors_so_far] = F1\n",
    "        \n",
    "        print(\"1er appel\")\n",
    "        print(\"residu:\")\n",
    "        plt.imshow(f_lambda_prime * F2)\n",
    "        plt.show()\n",
    "        print(\"F1:\")\n",
    "        plt.imshow(F1)\n",
    "        plt.show()\n",
    "        print(\"F2F1:\")\n",
    "        plt.imshow(f_lambda_prime * (F2 @ F1))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # arr_residual = F2\n",
    "        # get the k first elements [:k+1] and the next one (k+1)th as arr_residual\n",
    "        lst_nb_keep_values_constraints = [int(nb_keep_values_relaxed)] + [nb_keep_values] * nb_factors_so_far\n",
    "        f_lambda, (arr_residual, *lst_S[-nb_factors_so_far:]), _, _ = palm4msa(arr_X_target=arr_X_target, \n",
    "                                                     lst_S_init=[F2] + lst_S[-nb_factors_so_far:],\n",
    "                                                     nb_factors=nb_factors_so_far + 1,\n",
    "                                                     lst_nb_keep_values=lst_nb_keep_values_constraints,\n",
    "                                                     f_lambda_init=f_lambda_prime, \n",
    "                                                     nb_iter=nb_iter )\n",
    "        print(\"2eme appel\")\n",
    "        print(\"residu:\")\n",
    "        plt.imshow(arr_residual)\n",
    "        plt.show()\n",
    "        print(\"current factor:\")\n",
    "        plt.imshow(lst_S[-nb_factors_so_far])\n",
    "        plt.show()\n",
    "        print(\"reconstructed:\")\n",
    "        plt.imshow(f_lambda_prime * get_side_prod([arr_residual] + lst_S[-nb_factors_so_far:]))\n",
    "        plt.show()\n",
    "        #arr_residual = lst_S[k+1]\n",
    "        #arr_residual = T2\n",
    "\n",
    "        \n",
    "#         print(f_lambda_prime)\n",
    "    # last factor is residual of last palm4LED\n",
    "    lst_S[0] = arr_residual\n",
    "    if not right_to_left:\n",
    "        lst_S = [S.T for S in lst_S[::-1]]\n",
    "        \n",
    "    if len(lst_S) == 1:\n",
    "        arr_X_curr = f_lambda * lst_S[0]\n",
    "    else:\n",
    "        arr_X_curr = f_lambda * multi_dot(lst_S)\n",
    "\n",
    "    return f_lambda, lst_S, arr_X_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_side_prod():\n",
    "    nb_factors = 3\n",
    "    d = 32\n",
    "    nb_keep_values =64\n",
    "    factors = [projection_operator(np.random.rand(d, d), nb_keep_values) for _ in range(nb_factors)]\n",
    "    result = get_side_prod(factors)\n",
    "    truth = \n",
    "    visual_evaluation_palm4msa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_projection_operator():\n",
    "    matrix = np.random.permutation(16).reshape(4, 4) - 8\n",
    "    print(matrix)\n",
    "    matrix_proj = projection_operator(matrix, 5)\n",
    "    print(matrix_proj)\n",
    "test_projection_operator()\n",
    "\n",
    "def test_inplace_hardthreshold():\n",
    "    matrix = np.random.permutation(16).reshape(4, 4) -8\n",
    "    print(matrix)\n",
    "    inplace_hardthreshold(matrix, 5)\n",
    "    print(matrix)\n",
    "test_inplace_hardthreshold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visual_evaluation_palm4msa(target, init_factors, final_factors, result):\n",
    "    nb_factors = len(init_factors)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.imshow(target)\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.imshow(result)\n",
    "    print(\"Première ligne: Objectif \\t | \\t Résultat\")\n",
    "    print(\"Deuxième ligne: Les facteurs\")\n",
    "    print(\"Troisième ligne: Les facteurs initiaux\")\n",
    "    for i in range(nb_factors):\n",
    "        plt.subplot(3, nb_factors, nb_factors + (i+1))\n",
    "        plt.imshow(final_factors[i])\n",
    "        plt.subplot(3, nb_factors, nb_factors + nb_factors + (i+1))\n",
    "        plt.imshow(init_factors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadamard matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = 32\n",
    "nb_iter = 5000\n",
    "nb_factors = 5\n",
    "nb_keep_values = 64\n",
    "\n",
    "# lst_factors = [projection_operator(np.random.rand(d, d), nb_keep_values) for _ in range(nb_factors)]\n",
    "lst_factors = [np.eye(d) for _ in range(nb_factors)]\n",
    "#lst_factors = [np.random.rand(d, d) for _ in range(nb_factors)]\n",
    "lst_factors = [fac/norm(fac) for fac in lst_factors]\n",
    "lst_factors[-1] = np.zeros((d, d))  # VE\n",
    "_lambda = 1.\n",
    "had = hadamard(d)\n",
    "H =  had / norm(had, ord='fro')\n",
    "print(H)\n",
    "\n",
    "#final_lambda, final_factors, final_X = PALM4LED(H, lst_factors, [nb_keep_values for _ in range(nb_factors)], _lambda, nb_iter)\n",
    "final_lambda, final_factors, final_X = hierarchical_palm4msa(H, lst_factors, nb_keep_values, _lambda, nb_iter, right_to_left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lambda value: \" + str(final_lambda))\n",
    "visual_evaluation_palm4msa(H, lst_factors, final_factors, final_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-constructed sparse factorization\n",
    "\n",
    "Some sparse matrices are sampled randomly then their product is computed and considered as ground truth.\n",
    "The Hirerarchical PALM4LED algorithm is called with the real sparse matrices for initialisaiton of the factors.\n",
    "We check if the algorithm tries to find an other solution or stick to the initial matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 32\n",
    "nb_iter = 50\n",
    "nb_factors = 5\n",
    "nb_keep_values = 32\n",
    "\n",
    "lst_factors = [projection_operator(np.random.rand(d, d), nb_keep_values) for _ in range(nb_factors)]\n",
    "#lst_factors = [np.random.rand(d, d) for _ in range(nb_factors)]\n",
    "lst_factors = [fac/norm(fac) for fac in lst_factors]\n",
    "_lambda = 1.\n",
    "rebuilt_target = multi_dot(lst_factors)\n",
    "\n",
    "#final_lambda, final_factors, final_X = PALM4LED(H, lst_factors, [nb_keep_values for _ in range(nb_factors)], _lambda, nb_iter)\n",
    "final_lambda, final_factors, final_X = hierarchical_palm4msa(rebuilt_target, lst_factors, nb_keep_values, _lambda, nb_iter, left_to_right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Lambda value: \" + str(final_lambda))\n",
    "visual_evaluation_palm4msa(rebuilt_target, lst_factors, final_factors, final_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
